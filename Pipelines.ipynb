{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "Let's now take a closer look at pipelines. We will be using the **deep**doctection analyzer as an example. \n",
    "\n",
    "A pipeline is built as a sequence of tasks. These tasks are called pipeline components, pipeline backbones or services.\n",
    "\n",
    "![pipelines](./pics/dd_overview_pipeline.png)\n",
    "\n",
    "Once a pipeline is defined, images or documents can be processed. These are either pure image files (like JPG, PNG, TIFF) or PDF files. PDF files are read and processed page by page. Each PDF page is converted into a numpy array. \n",
    "\n",
    "We do not want to go into detail about the data structure at this point. If you want more information, please refer to the notebook **Diving_deeper_into_the_data_structure.ipynb**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdoctection as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the **deep**doctection analyzer. \n",
    "\n",
    "![pipeline](./pics/dd_pipeline.png)\n",
    "\n",
    "The default construction consists of several pipeline components: \n",
    "\n",
    "- Layout analysis (object detection)\n",
    "- Cell analysis in table regions (object detection)\n",
    "- Row and column analysis in table regions (object detection)\n",
    "- Table segmentation \n",
    "- Table segmentation refinement\n",
    "- OCR with Tesseract\n",
    "- Assignment of words to layout segments\n",
    "- Reading order of words within layout segments and reading order of layout segments.\n",
    "\n",
    "Therefore in total, three object detectors and one OCR are loaded.\n",
    "\n",
    "## Configuration\n",
    "\n",
    "![config](./pics/conf_dd_one_yaml.png)\n",
    "\n",
    "We see while initializing a configuration of the analyzer. The configuration is recorded in a `.yaml` file. You can find this file in the .cache dir of **deep**doctection.\n",
    "\n",
    "You can use the `.yaml` file to replace one model with e.g. a model trained on your own data. The easiest way is to add your model to the `ModelCatalog` and change the model in the `.yaml` file. Adding a model to the `ModelCatalog` is something that is covered in the section **Running_pre_trained_models_from_third_party_libraries.ipynb**.\n",
    "\n",
    "## Pipeline components\n",
    "\n",
    "Having a pipeline, you can list the components with `get_pipeline_info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'image_weights_layout_d2_model_0829999_layout_inf_only.pt',\n",
       " 1: 'sub_image_weights_cell_d2_model_1849999_cell_inf_only.pt',\n",
       " 2: 'sub_image_weights_item_d2_model_1639999_item_inf_only.pt',\n",
       " 3: 'table_segment',\n",
       " 4: 'table_segment_refine',\n",
       " 5: 'text_extract_tesseract',\n",
       " 6: 'matching',\n",
       " 7: 'text_order'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.get_pipeline_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'table_segment'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.get_pipeline_info(position=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not want to process any text extraction you can set `ocr=False` which gives you a shorter pipeline with fewer backbones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer(ocr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'image_weights_layout_d2_model_0829999_layout_inf_only.pt',\n",
       " 1: 'sub_image_weights_cell_d2_model_1849999_cell_inf_only.pt',\n",
       " 2: 'sub_image_weights_item_d2_model_1639999_item_inf_only.pt',\n",
       " 3: 'table_segment',\n",
       " 4: 'table_segment_refine'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.get_pipeline_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have access to pipeline components via `pipe_component_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<deepdoctection.pipe.layout.ImageLayoutService at 0x7fa9661000a0>,\n",
       " <deepdoctection.pipe.cell.SubImageLayoutService at 0x7fa965f708e0>,\n",
       " <deepdoctection.pipe.cell.SubImageLayoutService at 0x7fa965ff6df0>,\n",
       " <deepdoctection.pipe.segment.TableSegmentationService at 0x7fa965ff6c40>,\n",
       " <deepdoctection.pipe.refine.TableSegmentationRefinementService at 0x7fa965ff6a60>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.pipe_component_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout detection models\n",
    "\n",
    "The `ImageLayoutService` is responsible to detect the coarse layout structure over a full image. It has an object\n",
    "detector, which can be either a Tensorpack or a Detectron2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_layout_service = analyzer.pipe_component_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepdoctection.extern.d2detect.D2FrcnnDetector at 0x7faa61388d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_layout_service.predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a list of all categories that a model is able to detect. Moreover, you will find a unique description of each model in your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LayoutType.text>,\n",
       " <LayoutType.title>,\n",
       " <LayoutType.list>,\n",
       " <LayoutType.table>,\n",
       " <LayoutType.figure>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_layout_service.predictor.possible_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights_layout_d2_model_0829999_layout_inf_only.pt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_layout_service.predictor.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_service = analyzer.pipe_component_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LayoutType.cell>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_service.predictor.possible_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights_cell_d2_model_1849999_cell_inf_only.pt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_service.predictor.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR, matching and reading order\n",
    "\n",
    "Let's re-load the analyzer again, now with OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matching services maps words the layout segments by overlapping.  In order to do so, we need to specify what layout segments we want to consider. \n",
    "\n",
    "In this situation we do not consider `figure` as valid layout section and neglect any overlapping of a word with a `figure` segment. Of course, this can be changed by adding `figure` to the list of `parent_categories`.\n",
    "\n",
    "Orphan words with no overlapping with any layout segment will be set aside. There are customizations that describe how to deal with orphan words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_service = analyzer.pipe_component_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_categories: ['text', 'title', 'cell', 'list'], child_categories: word\n"
     ]
    }
   ],
   "source": [
    "print(f\"parent_categories: {match_service.parent_categories}, child_categories: {match_service.child_categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a matching rule and a threshold to specifiy. We also need to choose whether we want to assign a word to \n",
    "multiple layout sections. When setting `max_parent_only=True` we consider only the largest overlapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching_rule: ioa \n",
      " match_service: 0.6 \n",
      " max_parent_only: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"matching_rule: {match_service.matching_rule} \\n match_threshold: {match_service.threshold} \\n max_parent_only: {match_service.max_parent_only}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customizing the reading order requires some additional terminology which goes beyond the introduction. \n",
    "We refer to [this page](https://deepdoctection.readthedocs.io/en/latest/tutorials/layout_parsing_structure) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_order_service = analyzer.pipe_component_list[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LayoutType.word>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_order_service.text_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LayoutType.title>, <LayoutType.text>, <LayoutType.list>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_order_service.floating_text_block_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LayoutType.title>,\n",
       " <LayoutType.text>,\n",
       " <LayoutType.list>,\n",
       " <LayoutType.cell>,\n",
       " <CellType.header>,\n",
       " <CellType.body>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_order_service.text_block_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-doc-pt",
   "language": "python",
   "name": "deep-doc-pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
