{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a custom pipeline\n",
    "\n",
    "The **deep**doctection analyzer is an example of a Document Layout Analysis pipeline. In this tutorial we'll show you the concepts so that you can build a pipeline youself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import deepdoctection as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is not that difficult: There are models that fulfill a given task, there are pipeline components or pipeline backbones that invoke models and take care of pre- and post-processing results. There are also pipeline backbones that do not invoke models but only consolidate results. \n",
    "\n",
    "And there is the pipeline that puts everything together.\n",
    "\n",
    "## Catalog and registries\n",
    "\n",
    "You can get the essential information for pre-trained model from the `ModelCatalog`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.print_model_infos(add_description=False,add_config=False,add_categories=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select fasttext language detector. We need the categories that the model predicts and the model wrapper. `fasttext/lid.176.bin` is just an artefact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=dd.ModelCatalog.get_profile(\"fasttext/lid.176.bin\").categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FasttextLangDetector'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.ModelCatalog.get_profile(\"fasttext/lid.176.bin\").model_wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download `lid.176.bin` with help of the `ModelDownloadManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1219 17:00.25 @fs.py:94]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mFile lid.176.bin exists! Skip download.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "path_weights=dd.ModelDownloadManager.maybe_download_weights_and_configs(\"fasttext/lid.176.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model wrapper\n",
    "\n",
    "We know from the `ModelCatalog` which wrapper we must use for the fasttext model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fast_text = dd.FasttextLangDetector(path_weights, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not done yet, because we still need to choose how to extract text. Let's simply stick to Tesseract and use the default english setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_ocr_config_path = dd.get_configs_dir_path() / \"dd/conf_tesseract.yaml\"  # This file will be in you .cache if you ran the analyzer before. \n",
    "# Otherwise make sure to copy the file from 'configs/conf_tesseract.yaml'\n",
    "\n",
    "tesseract_ocr = dd.TesseractOcrDetector(tess_ocr_config_path.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline backbone\n",
    "\n",
    "Similar to models we have a pipeline component registry. Having this starting point we can select the right backbone. Check the API documentation to see what the components are used for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SubImageLayoutService': deepdoctection.pipe.cell.SubImageLayoutService,\n",
       " 'ImageCroppingService': deepdoctection.pipe.common.ImageCroppingService,\n",
       " 'MatchingService': deepdoctection.pipe.common.MatchingService,\n",
       " 'PageParsingService': deepdoctection.pipe.common.PageParsingService,\n",
       " 'LanguageDetectionService': deepdoctection.pipe.language.LanguageDetectionService,\n",
       " 'ImageLayoutService': deepdoctection.pipe.layout.ImageLayoutService,\n",
       " 'LMTokenClassifierService': deepdoctection.pipe.lm.LMTokenClassifierService,\n",
       " 'LMSequenceClassifierService': deepdoctection.pipe.lm.LMSequenceClassifierService,\n",
       " 'TableSegmentationRefinementService': deepdoctection.pipe.refine.TableSegmentationRefinementService,\n",
       " 'TableSegmentationService': deepdoctection.pipe.segment.TableSegmentationService,\n",
       " 'TextExtractionService': deepdoctection.pipe.text.TextExtractionService,\n",
       " 'TextOrderService': deepdoctection.pipe.text.TextOrderService,\n",
       " 'SimpleTransformService': deepdoctection.pipe.transform.SimpleTransformService}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.pipeline_component_registry.get_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext language detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_detect_comp = dd.LanguageDetectionService(fast_text,text_detector=tesseract_ocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build our very simple pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_comp_list = [lang_detect_comp]\n",
    "pipe = dd.DoctectionPipe(pipeline_component_list=pipe_comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path.cwd() / \"pics/samples/sample_3\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/samples/sample_3/sample_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the pipe, we get the language in which the document was written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|                                                                                                                                                                                                 |1/?[00:00<00:00,1291.75it/s]\n",
      "\u001b[32m[1219 17:03.05 @doctectionpipe.py:124]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mProcessing sample_3.png\u001b[0m\n",
      "\u001b[32m[1219 17:03.08 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mLanguageDetectionService total: 2.6558 sec.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Languages.german>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When getting the text, the response is somewhat disappointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for that is that `LanguageDetectionService` is not responsible for extracting text. It has an OCR model, but the output is only used as input feed to the language detector. The text however is not persisted. If we had added a `TextExtractionService` before `LanguageDetectionService` we could have omitted the OCR model in the `LanguageDetectionService`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesseract OCR detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesseract_ocr = dd.TesseractOcrDetector(tess_ocr_config_path.as_posix(),[\"LANGUAGES=deu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LANGUAGES': 'deu', 'LINES': False, 'psm': 11}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesseract_ocr.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting run_time_ocr_language_selection=True will dynamically select the OCR model for text extraction based on \n",
    "# the predicted languages. This helps to get much improved OCR results, if you have documents with various languages.\n",
    "\n",
    "text_comp = dd.TextExtractionService(tesseract_ocr, run_time_ocr_language_selection=True)\n",
    "pipe_comp_list.append(text_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|                                                                                                                                                                                                 |1/?[00:00<00:00,1357.82it/s]\n",
      "\u001b[32m[1219 17:03.17 @doctectionpipe.py:124]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mProcessing sample_3.png\u001b[0m\n",
      "\u001b[32m[1219 17:03.20 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mLanguageDetectionService total: 2.6773 sec.\u001b[0m\n",
      "\u001b[32m[1219 17:03.22 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mTextExtractionService total: 2.7287 sec.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something unexpected. Why don't we generate any text? We can clearly see that the `TextExtractionService` did its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553, 'Anleihemärkte', [137.0, 158.0, 472.0, 195.0], None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sample = dp.words[0]\n",
    "len(dp.words), word_sample.characters, word_sample.bbox, word_sample.reading_order "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is, that we do not have inferred a reading order. If there is no reading order, there is no contiguous text. We treat text extraction as a character recognition problem only. If we want a reading order of predicted words, we need to do it ourself. So let's add the 'TextOrderService'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_comp = dd.TextOrderService(text_container=dd.LayoutType.word)\n",
    "pipe_comp_list.append(order_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least, we got some text. The beginning sounds good. But once the text comes to the region where the second and third column also have text lines, the order service does not distinguish between columns. So we must identify columns. For that we use the layout analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|                                                                                                                                                                                                 |1/?[00:00<00:00,1212.23it/s]\n",
      "\u001b[32m[1219 17:03.25 @doctectionpipe.py:124]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mProcessing sample_3.png\u001b[0m\n",
      "\u001b[32m[1219 17:03.28 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mLanguageDetectionService total: 2.674 sec.\u001b[0m\n",
      "\u001b[32m[1219 17:03.30 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mTextExtractionService total: 2.8881 sec.\u001b[0m\n",
      "\u001b[32m[1219 17:03.30 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mTextOrderService total: 0.0146 sec.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Anleihemärkte im Geschäftsjahr bis zum 31.12.2018 Schwieriges Marktumfeld Entwicklung der Leitzinsen in den USA und im Euroraum Die internationalen Anleihe- %p.a. märkte entwickelten sich im Geschäftsjahr 2018 unter- schiedlich und phasenweise sehr volatil. Dabei machte sich bei den Investoren zunehmend Nervosität breit, was in steigen- -1 u u u u u u u u u u u den Risikoprämien zum Aus- 12/08 12/09 12/10 12/11 12/12 12/13 12/14 12/15 12/16 12/17 12/18 druck kam. Grund hierfür waren BE Fed-Leitzins Quelle: Thomson Financial Datastream Turbulenzen auf der weltpoli- BE E28-Leitzins Stand: 31.12.2018 tischen Bühne, die die politi- schen Risiken erhöhten. Dazu zählten unter anderem populis- Zinswende nach Rekordtiefs Fiskalpolitik des US-Präsidenten tische Strömungen nicht nur bei Anleiherenditen? Donald Trump in Form von in den USA und Europa, auch Im Berichtszeitraum kam es an Steuererleichterungen und einer in den Emerging Markets, wie den Anleihemärkten - wenn Erhöhung der Staatsausgaben zuletzt in Brasilien und Mexiko, auch uneinheitlich und unter- noch befeuert wurde. Vor die- wo Populisten in die Regie- schiedlich stark ausgeprägt - sem Hintergrund verzeichneten rungen gewählt wurden. Der unter Schwankungen zu stei- die US-Bondmärkte einen spür- eskalierende Handelskonflikt genden Renditen auf teilweise baren Renditeanstieg, der mit zwischen den USA einerseits immer noch sehr niedrigem merklichen Kursermäßigungen sowie Europa und China ande- Niveau, begleitet von nachge- einherging. Per saldo stiegen rerseits tat sein übriges. Zudem benden Kursen. Dabei konnten die Renditen zehnjähriger US- ging Italien im Rahmen seiner sich die Zinsen vor allem in den Staatsanleihen auf Jahressicht Haushaltspolitik auf Konfronta- USA weiter von ihren histori- von 2,4% p.a. auf 3,1% p.a. tionskurs zur Europäischen Uni- schen Tiefs lösen. Gleichzeitig on (EU). Darüber hinaus verun- wurde die Zentralbankdivergenz Diese Entwicklung in den USA sicherte weiterhin der drohende zwischen den USA und dem hatte auf den Euroraum jedoch Brexit die Marktteilnehmer, Euroraum immer deutlicher. An- nur phasenweise und partiell, insbesondere dahingehend, ob gesichts des Wirtschaftsbooms insgesamt aber kaum einen der mögliche Austritt des Ver- in den USA hob die US-Noten- zinstreibenden Effekt auf Staats- einigten Königreiches aus der bank Fed im Berichtszeitraum anleihen aus den europäischen EU geordnet oder - ohne ein den Leitzins in vier Schritten Kernmärkten wie beispielsweise weiter um einen Prozentpunkt Deutschland und Frankreich. Übereinkommen - ungeordnet vollzogen wird. Im Gegensatz auf einen Korridor von 2,25% - So gaben zehnjährige deutsche zu den politischen Unsicher- 2,50% p.a. an. Die Europäische Bundesanleihen im Jahresver- heiten standen die bislang eher Zentralbank (EZB) hingegen lauf 2018 unter Schwankungen zuversichtlichen, konventionel- hielt an ihrer Nullzinspolitik fest per saldo sogar von 0,42% p.a. len Wirtschaftsindikatoren. So und die Bank of Japan beließ auf 0,25% p. a. nach. Vielmehr expandierte die Weltwirtschaft ihren Leitzins bei -0,10% p.a. standen die Anleihemärkte kräftig, wenngleich sich deren Die Fed begründete ihre Zinser- der Euroländer - insbeson- Wachstum im Laufe der zwei- dere ab dem zweiten Quartal höhungen mit der Wachstums- ten Jahreshälfte 2018 etwas beschleunigung und der Voll- 2018 - unter dem Einfluss der verlangsamte. Die Geldpolitik beschäftigung am Arbeitsmarkt politischen und wirtschaftlichen war historisch gesehen immer in den USA. Zinserhöhungen Entwicklung in der Eurozone, noch sehr locker, trotz der welt- vor allem in den Ländern mit ermöglichten der US-Notenbank weit sehr hohen Verschuldung einer Überhitzung der US-Wirt- hoher Verschuldung und nied- und der Zinserhöhungen der schaft vorzubeugen, die durch rigem Wirtschaftswachstum. US-Notenbank. die prozyklische expansive In den Monaten Mai und Juni'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout service\n",
    "\n",
    "It now depends on whether we use Tensorflow or PyTorch. We opt for PyTorch, just because the model runs on a CPU.\n",
    "Make sure, that the model has been loaded to your .cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': <LayoutType.text>,\n",
       " '2': <LayoutType.title>,\n",
       " '3': <LayoutType.list>,\n",
       " '4': <LayoutType.table>,\n",
       " '5': <LayoutType.figure>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_weights = dd.ModelCatalog.get_full_path_weights(\"layout/d2_model_0829999_layout_inf_only.pt\")\n",
    "path_configs = dd.ModelCatalog.get_full_path_configs(\"layout/d2_model_0829999_layout_inf_only.pt\")\n",
    "categories = dd.ModelCatalog.get_profile(\"layout/d2_model_0829999_layout_inf_only.pt\").categories\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_detector = dd.D2FrcnnDetector(path_configs,path_weights,categories,device=\"cpu\")\n",
    "layout_comp = dd.ImageLayoutService(layout_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure, that the `ImageLayoutService` has been invoked before `TextOrderService`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_comp_list.insert(0,layout_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', '')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.text, dp.layouts[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this looks weird again, doesn't it? However the reason is still quite simple. We now get an empty text string because once we have a non-empty `dp.layouts` the routine responsible for creating `dp.text` will try to get the text from the `Layout`'s. But we haven't run any method that maps a `word` to some `Layout` object. We need to specify this by applying a `MatchingService`. We will also have to slightly change the configuration of the  `TextOrderService`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_comp = dd.MatchingService(parent_categories=[\"text\",\"title\",\"list\",\"table\",\"figure\"], child_categories=[\"word\"],\n",
    "                             matching_rule = 'ioa', threshold=0.6) # same setting as for the deepdoctection analyzer\n",
    "\n",
    "order_comp = dd.TextOrderService(text_container=dd.LayoutType.word,\n",
    "                                 floating_text_block_names=[\"text\",\"title\",\"list\", \"figure\"],\n",
    "                                 text_block_names=[\"text\",\"title\",\"list\",\"table\",\"figure\"])\n",
    "\n",
    "pipe_comp_list = [layout_comp, lang_detect_comp, text_comp, map_comp, order_comp]\n",
    "pipe = dd.DoctectionPipe(pipeline_component_list=pipe_comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|                                                                                                                                                                                                 |1/?[00:00<00:00,1237.99it/s]\n",
      "\u001b[32m[1219 17:03.41 @doctectionpipe.py:124]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mProcessing sample_3.png\u001b[0m\n",
      "\u001b[32m[1219 17:03.43 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mImageLayoutService total: 1.6445 sec.\u001b[0m\n",
      "\u001b[32m[1219 17:03.45 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mLanguageDetectionService total: 2.6846 sec.\u001b[0m\n",
      "\u001b[32m[1219 17:03.48 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mTextExtractionService total: 2.8263 sec.\u001b[0m\n",
      "\u001b[32m[1219 17:03.48 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mMatchingService total: 0.0041 sec.\u001b[0m\n",
      "\u001b[32m[1219 17:03.48 @context.py:131]\u001b[0m  \u001b[32mINF\u001b[0m  \u001b[37mTextOrderService total: 0.0387 sec.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAnleihemärkte im Geschäftsjahr bis zum 31.12.2018\\nSchwieriges Marktumfeld Die internationalen Anleihe- märkte entwickelten sich im Geschäftsjahr 2018 unter- schiedlich und phasenweise sehr volatil. Dabei machte sich bei den Investoren zunehmend Nervosität breit, was in steigen- den Risikoprämien zum Aus- druck kam. Grund hierfür waren Turbulenzen auf der weltpoli- tischen Bühne, die die politi- schen Risiken erhöhten. Dazu zählten unter anderem populis- tische Strömungen nicht nur in den USA und Europa, auch in den Emerging Markets, wie zuletzt in Brasilien und Mexiko, wo Populisten in die Regie- rungen gewählt wurden. Der eskalierende Handelskonflikt zwischen den USA einerseits sowie Europa und China ande- rerseits tat sein übriges. Zudem ging Italien im Rahmen seiner Haushaltspolitik auf Konfronta- tionskurs zur Europäischen Uni- on (EU). Darüber hinaus verun- sicherte weiterhin der drohende Brexit die Marktteilnehmer, insbesondere dahingehend, ob der mögliche Austritt des Ver- einigten Königreiches aus der EU geordnet oder - ohne ein Übereinkommen - ungeordnet vollzogen wird. Im Gegensatz zu den politischen Unsicher- heiten standen die bislang eher zuversichtlichen, konventionel- len Wirtschaftsindikatoren. So expandierte die Weltwirtschaft kräftig, wenngleich sich deren Wachstum im Laufe der zwei- ten Jahreshälfte 2018 etwas verlangsamte. Die Geldpolitik war historisch gesehen immer noch sehr locker, trotz der welt- weit sehr hohen Verschuldung und der Zinserhöhungen der US-Notenbank.\\nEntwicklung der Leitzinsen in den USA und im Euroraum %p.a.\\nFiskalpolitik des US-Präsidenten Donald Trump in Form von Steuererleichterungen und einer Erhöhung der Staatsausgaben noch befeuert wurde. Vor die- sem Hintergrund verzeichneten die US-Bondmärkte einen spür- baren Renditeanstieg, der mit merklichen Kursermäßigungen einherging. Per saldo stiegen die Renditen zehnjähriger US- Staatsanleihen auf Jahressicht von 2,4% p.a. auf 3,1% p.a.\\nbei Anleiherenditen? Im Berichtszeitraum kam es an den Anleihemärkten - wenn auch uneinheitlich und unter- schiedlich stark ausgeprägt - unter Schwankungen zu stei- genden Renditen auf teilweise immer noch sehr niedrigem Niveau, begleitet von nachge- benden Kursen. Dabei konnten sich die Zinsen vor allem in den USA weiter von ihren histori- schen Tiefs lösen. Gleichzeitig wurde die Zentralbankdivergenz zwischen den USA und dem Euroraum immer deutlicher. An- gesichts des Wirtschaftsbooms in den USA hob die US-Noten- bank Fed im Berichtszeitraum den Leitzins in vier Schritten weiter um einen Prozentpunkt auf einen Korridor von 2,25% - 2,50% p.a. an. Die Europäische Zentralbank (EZB) hingegen hielt an ihrer Nullzinspolitik fest und die Bank of Japan beließ ihren Leitzins bei -0,10% p.a. Die Fed begründete ihre Zinser- höhungen mit der Wachstums- beschleunigung und der Voll- beschäftigung am Arbeitsmarkt in den USA. Zinserhöhungen ermöglichten der US-Notenbank einer Überhitzung der US-Wirt- schaft vorzubeugen, die durch die prozyklische expansive\\nDiese Entwicklung in den USA hatte auf den Euroraum jedoch nur phasenweise und partiell, insgesamt aber kaum einen zinstreibenden Effekt auf Staats- anleihen aus den europäischen Kernmärkten wie beispielsweise Deutschland und Frankreich. So gaben zehnjährige deutsche Bundesanleihen im Jahresver- lauf 2018 unter Schwankungen per saldo sogar von 0,42% p.a. auf 0,25% p. a. nach. Vielmehr standen die Anleihemärkte der Euroländer - insbeson- dere ab dem zweiten Quartal 2018 - unter dem Einfluss der politischen und wirtschaftlichen Entwicklung in der Eurozone, vor allem in den Ländern mit hoher Verschuldung und nied- rigem Wirtschaftswachstum. In den Monaten Mai und Juni'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we got it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-doc-pt",
   "language": "python",
   "name": "deep-doc-pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
