{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a custom pipeline\n",
    "\n",
    "The **deep**doctection analyzer is an example of a Document Layout Analysis pipeline. In this tutorial we'll show you the concepts so that you can build a pipeline youself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import deepdoctection as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is not that difficult: There are models that fulfill a given task, there are pipeline components or pipeline backbones that invoke models and take care of pre- and post-processing results. There are also pipeline backbones that do not invoke models but only consolidate results. \n",
    "\n",
    "And there is the pipeline that puts everything together.\n",
    "\n",
    "## Catalog and registries\n",
    "\n",
    "You can get the essential information for pre-trained model from the `ModelCatalog`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.print_model_infos(add_description=False,add_config=False,add_categories=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select fasttext language detector. We need the categories that the model predicts and the model wrapper. `fasttext/lid.176.bin` is just an artefact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=dd.ModelCatalog.get_profile(\"fasttext/lid.176.bin\").categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FasttextLangDetector'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.ModelCatalog.get_profile(\"fasttext/lid.176.bin\").model_wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download `lid.176.bin` with help of the `ModelDownloadManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weights=dd.ModelDownloadManager.maybe_download_weights_and_configs(\"fasttext/lid.176.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model wrapper\n",
    "\n",
    "We know from the `ModelCatalog` which wrapper we must use for the fasttext model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text = dd.FasttextLangDetector(path_weights, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not done yet, because we still need to choose how to extract text. Let's simply stick to Tesseract and use the default english setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_ocr_config_path = dd.get_configs_dir_path() / \"dd/conf_tesseract.yaml\"  # This file will be in you .cache if you ran the analyzer before. \n",
    "# Otherwise make sure to copy the file from 'configs/conf_tesseract.yaml'\n",
    "\n",
    "tesseract_ocr = dd.TesseractOcrDetector(tess_ocr_config_path.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline backbone\n",
    "\n",
    "As with models et all. we have a pipeline component registry. Having this starting point we can select the right backbone. Check the API documentation to see what the components are used for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SubImageLayoutService': deepdoctection.pipe.cell.SubImageLayoutService,\n",
       " 'ImageCroppingService': deepdoctection.pipe.common.ImageCroppingService,\n",
       " 'MatchingService': deepdoctection.pipe.common.MatchingService,\n",
       " 'PageParsingService': deepdoctection.pipe.common.PageParsingService,\n",
       " 'LanguageDetectionService': deepdoctection.pipe.language.LanguageDetectionService,\n",
       " 'ImageLayoutService': deepdoctection.pipe.layout.ImageLayoutService,\n",
       " 'LMTokenClassifierService': deepdoctection.pipe.lm.LMTokenClassifierService,\n",
       " 'LMSequenceClassifierService': deepdoctection.pipe.lm.LMSequenceClassifierService,\n",
       " 'TableSegmentationRefinementService': deepdoctection.pipe.refine.TableSegmentationRefinementService,\n",
       " 'TableSegmentationService': deepdoctection.pipe.segment.TableSegmentationService,\n",
       " 'TextExtractionService': deepdoctection.pipe.text.TextExtractionService,\n",
       " 'TextOrderService': deepdoctection.pipe.text.TextOrderService,\n",
       " 'SimpleTransformService': deepdoctection.pipe.transform.SimpleTransformService}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.pipeline_component_registry.get_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext language detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_detect_comp = dd.LanguageDetectionService(fast_text,text_detector=tesseract_ocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build our very simple pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_comp_list = [lang_detect_comp]\n",
    "pipe = dd.DoctectionPipe(pipeline_component_list=pipe_comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(dd.get_package_path()) / \"notebooks/pics/samples/sample_3\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/samples/sample_3/sample_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the pipe, we get the language in which the document was written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When getting the text, the response is somewhat disappointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for that is that `LanguageDetectionService` is not responsible for extracting text. It has an OCR model, but the output is only used as input feed to the language detector. The text however is not persisted. If we had added a `TextExtractionService` before `LanguageDetectionService` we could have omitted the OCR model in the `LanguageDetectionService`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesseract OCR detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesseract_ocr = dd.TesseractOcrDetector(tess_ocr_config_path.as_posix(),[\"LANGUAGES=deu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LANGUAGES': 'deu', 'LINES': False, 'psm': 11}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesseract_ocr.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting run_time_ocr_language_selection=True will dynamically select the OCR model for text extraction based on \n",
    "# the predicted languages. This helps to get much improved OCR results, if you have documents with various languages.\n",
    "\n",
    "text_comp = dd.TextExtractionService(tesseract_ocr, run_time_ocr_language_selection=True)\n",
    "pipe_comp_list.append(text_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something unexpected. Why don't we generate any text? We can clearly see that the `TextExtractionService` did its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553, 'Anleihem√§rkte', [137.0, 158.0, 472.0, 195.0], None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sample = dp.words[0]\n",
    "len(dp.words), word_sample.characters, word_sample.bbox, word_sample.reading_order "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is, that we do not have inferred a reading order. If there is no reading order, there is no contiguous text. We treat text extraction as a character recognition problem only. If we want a reading order of predicted words, we need to do it ourself. So let's add the 'TextOrderService'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_comp = dd.TextOrderService(text_container=dd.LayoutType.word)\n",
    "pipe_comp_list.append(order_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least, we got some text. The beginning sounds good. But once the text comes to the region where the second and third column also have text lines, the order service does not distinguish between columns. So we must identify columns. For that we use the layout analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout service\n",
    "\n",
    "It now depends on whether we use Tensorflow or PyTorch. We opt for PyTorch, just because the model runs on a CPU.\n",
    "Make sure, that the model has been loaded to your .cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': <LayoutType.text>,\n",
       " '2': <LayoutType.title>,\n",
       " '3': <LayoutType.list>,\n",
       " '4': <LayoutType.table>,\n",
       " '5': <LayoutType.figure>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_weights = dd.ModelCatalog.get_full_path_weights(\"layout/d2_model_0829999_layout_inf_only.pt\")\n",
    "path_configs = dd.ModelCatalog.get_full_path_configs(\"layout/d2_model_0829999_layout_inf_only.pt\")\n",
    "categories = dd.ModelCatalog.get_profile(\"layout/d2_model_0829999_layout_inf_only.pt\").categories\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_detector = dd.D2FrcnnDetector(path_configs,path_weights,categories,device=\"cpu\")\n",
    "layout_comp = dd.ImageLayoutService(layout_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure, that the `ImageLayoutService` has been invoked before `TextOrderService`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_comp_list.insert(0,layout_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', '')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.text, dp.layouts[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this looks weird again, doesn't it? However the reason is still quite simple. We now get an empty text string because once we have a non-empty `dp.layouts` the routine responsible for creating `dp.text` will try to get the text from the `Layout`'s. But we haven't run any method that maps a `word` to some `Layout` object. We need to specify this by applying a `MatchingService`. We will also have to slightly change the configuration of the  `TextOrderService`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_comp = dd.MatchingService(parent_categories=[\"text\",\"title\",\"list\",\"table\",\"figure\"], child_categories=[\"word\"],\n",
    "                             matching_rule = 'ioa', threshold=0.6) # same setting as for the deepdoctection analyzer\n",
    "\n",
    "order_comp = dd.TextOrderService(text_container=dd.LayoutType.word,\n",
    "                                 floating_text_block_names=[\"text\",\"title\",\"list\", \"figure\"],\n",
    "                                 text_block_names=[\"text\",\"title\",\"list\",\"table\",\"figure\"])\n",
    "\n",
    "pipe_comp_list = [layout_comp, lang_detect_comp, text_comp, map_comp, order_comp]\n",
    "pipe = dd.DoctectionPipe(pipeline_component_list=pipe_comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipe.analyze(path=image_path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we got it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-doc-pt",
   "language": "python",
   "name": "deep-doc-pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
